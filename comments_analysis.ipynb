{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from string import digits\n",
    "\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean file, Return word list\n",
    "def cleansed_text(file_name):\n",
    "    # Open file\n",
    "    text_file = open(f\"{current_directory}/{file_name}\")\n",
    "    # Read text\n",
    "    text = text_file.read().lower()\n",
    "    # Remove digits\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    # Remove punctuations\n",
    "    text = text.translate(text.maketrans('', '', string.punctuation))\n",
    "    # Remove newline\n",
    "    text = text.replace(\"/n\", \" \")\n",
    "    # Tokenize\n",
    "    text = text.split(\" \")\n",
    "    # Close file\n",
    "    text_file.close()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7422680412371134\n"
     ]
    }
   ],
   "source": [
    "# Type token Ratio\n",
    "\n",
    "def get_ttr(file_name):\n",
    "    text_list = cleansed_text(file_name)\n",
    "    unique_words = []\n",
    "    \n",
    "    # create a list of unique words\n",
    "    for word in text_list:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "\n",
    "    # calculate TTR\n",
    "    ttr = len(unique_words) / len(text_list)\n",
    "    \n",
    "    return ttr\n",
    "\n",
    "# Test\n",
    "# print(get_ttr(\"Amish and Mennonite_amish-apple-dumplings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.65979381443299\n"
     ]
    }
   ],
   "source": [
    "# Average word length\n",
    "\n",
    "def avg_word_len(file_name):\n",
    "    text_list = cleansed_text(file_name)\n",
    "    \n",
    "    count = 0\n",
    "    for word in text_list:\n",
    "        count += len(word)\n",
    "    \n",
    "    avg_len = count / len(text_list)\n",
    "    return avg_len\n",
    "\n",
    "# Test\n",
    "# print(avg_word_len(\"Amish and Mennonite_amish-apple-dumplings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# Total number of words\n",
    "\n",
    "def total_num_words(file_name):\n",
    "    text_list = cleansed_text(file_name)\n",
    "    total_number_words = len(text_list)\n",
    "    return total_number_words\n",
    "\n",
    "# Test\n",
    "# print(total_num_words(\"Amish and Mennonite_amish-apple-dumplings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boy', 'parent', 'generation', 'aunt', 'daddy', 'fiancé', 'cousin’s wife', 'granddaughter', 'girl', 'first cousin once removed', 'boyfriend', 'relationship', 'niece', 'son-in-law', 'wife', 'friends', 'great-grandmother', 'mom', 'family', 'great-uncle', 'peer', 'grandpa', 'brother-in-law', 'grandfather', 'baby boy', 'pet', 'warm', 'grandmother', 'gathering', 'teen', 'great-aunt', 'cousin', 'partner', 'fiance', 'daughter', 'mommy', 'house', 'dad', 'cat', 'close', 'husband', 'daughter-in-law', 'holiday', 'pa', 'younger', 'holidays', 'love', 'young', 'friend', 'brother', 'father', 'household', 'old', 'girl twins', 'great-grandfather', 'twin boys', 'dog', 'kin', 'father-in-law', 'mother', 'child', 'sibling', 'older', 'grandson', 'teacher', 'sister', 'cousin’s husband', 'son', 'girlfriend', 'nephew', 'uncle', 'sister-in-law'}\n"
     ]
    }
   ],
   "source": [
    "# Top 10 most frequently used words (excluding function words)\n",
    "\n",
    "# List of function words\n",
    "def get_function_words():\n",
    "    # Open and read file\n",
    "    fhand = open(f\"{current_directory}/reference_data/function_words.txt\")\n",
    "    function_words_list = []\n",
    "    \n",
    "    for line in fhand:\n",
    "        function_words_list.append(line.strip())\n",
    "        \n",
    "    # Close file\n",
    "    fhand.close()\n",
    "        \n",
    "    return function_words_list\n",
    "\n",
    "function_words = get_function_words()\n",
    "    \n",
    "\n",
    "# Check if word is a function\n",
    "def is_function_word(word):\n",
    "    if word in function_words:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Return top 10 most frequently used words\n",
    "def most_freq_words(file_name):\n",
    "    text_list = cleansed_text(file_name)\n",
    "    \n",
    "    # Exclude function words\n",
    "    text_nofw = [word for word in text_list if not is_function_word(word)]\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_counter = Counter(text_nofw)\n",
    "    \n",
    "    # Retrieve the top 10 most frequent words\n",
    "    top10_dict = word_counter.most_common(11)\n",
    "    \n",
    "    # Return the top 10 words\n",
    "    top10 = []\n",
    "    for word, count in top10_dict:\n",
    "        if word != '':\n",
    "            top10.append(word)\n",
    "        \n",
    "    return top10\n",
    "\n",
    "# Test\n",
    "# print(most_freq_words(\"Amish and Mennonite_amish-baked-oatmeal.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('just', 'as'), ('as', 'written'), ('i', 'used'), ('coconut', 'oil'), ('was', 'wonderful'), ('brown', 'sugar'), ('don’t', 'like'), ('too', 'sweet'), ('sweet', 'and'), ('blueberries', 'and')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 bigrams\n",
    "\n",
    "def top_bigrams(file_name):\n",
    "    words = cleansed_text(file_name)\n",
    "    \n",
    "    # Retrieve all bigrams\n",
    "    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
    "\n",
    "    # Frequency of each bigram\n",
    "    bigrams_freq = Counter(bigrams)\n",
    "\n",
    "    # Sort bigrams by in descending order\n",
    "    sorted_bigrams = sorted(bigrams_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Remove unecessary trailing whitespace\n",
    "    cleaned_bigrams = {}\n",
    "    for words, count in sorted_bigrams:\n",
    "        if '' in words:\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_bigrams[words] = count\n",
    "        \n",
    "    # Return the top 10 most frequent bigrams\n",
    "    top10_bigrams = []\n",
    "    num = 0\n",
    "    for word1, word2 in cleaned_bigrams:\n",
    "        num += 1\n",
    "        top10_bigrams.append((word1, word2))\n",
    "        if num == 10:\n",
    "            break\n",
    "\n",
    "    return top10_bigrams\n",
    "\n",
    "# Test\n",
    "# print(top_bigrams(\"Amish and Mennonite_amish-baked-oatmeal.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('just', 'as', 'written'), ('too', 'sweet', 'and'), ('i', 'made', 'it'), ('made', 'it', 'just'), ('it', 'just', 'as'), ('as', 'written', 'and'), ('written', 'and', 'was'), ('and', 'was', 'wonderful'), ('did', 'some', 'experimentations'), ('i', 'used', 'coconut')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 trigrams\n",
    "            \n",
    "def top_trigrams(file_name):\n",
    "    words = cleansed_text(file_name)\n",
    "    \n",
    "    # Retrieve all trigrams\n",
    "    trigrams = [(words[i], words[i+1], words[i+2]) for i in range(len(words)-2)]\n",
    "\n",
    "    # Frequency of each bigram\n",
    "    trigrams_freq = Counter(trigrams)\n",
    "\n",
    "    # Sort bigrams by in descending order\n",
    "    sorted_trigrams = sorted(trigrams_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Remove unecessary trailing whitespace\n",
    "    cleaned_trigrams = {}\n",
    "    for words, count in sorted_trigrams:\n",
    "        if '' in words:\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_trigrams[words] = count\n",
    "        \n",
    "    # Return the top 10 most frequent bigrams\n",
    "    top10_trigrams = []\n",
    "    num = 0\n",
    "    for word1, word2, word3 in cleaned_trigrams:\n",
    "        num += 1\n",
    "        top10_trigrams.append((word1, word2, word3))\n",
    "        if num == 10:\n",
    "            break\n",
    "\n",
    "    return top10_trigrams\n",
    "\n",
    "# Test\n",
    "# print(top_trigrams(\"Amish and Mennonite_amish-baked-oatmeal.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output txt file with all texts combined\n",
    "                \n",
    "def combined_texts():\n",
    "    directory = f\"{current_directory}/text\"\n",
    "    \n",
    "    result_str = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file = os.path.join(directory, filename)\n",
    "        \n",
    "        if \".DS_Store\" in file:\n",
    "            continue\n",
    "        elif os.path.isfile(file):\n",
    "            # Open and read file\n",
    "            text_file = open(file, \"r\")\n",
    "            text = text_file.read()\n",
    "            # Close text file\n",
    "            text_file.close()\n",
    "            # Add text to result string\n",
    "            result_str = \" \".join([result_str, text])\n",
    "    \n",
    "    # Change directory\n",
    "    cur_directory = os.chdir(current_directory)\n",
    "    \n",
    "    with open(f'all_comments.txt', 'w') as f:\n",
    "        f.write(result_str)\n",
    "        f.close()\n",
    "\n",
    "# combined_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of words or ngrams to a string\n",
    "\n",
    "def list_to_str(lst):\n",
    "    s = ''\n",
    "    for i in range(len(lst)):  # for each tuple\n",
    "\n",
    "        # Create a string from a tuple (e.g., \"the united nations\")\n",
    "        if type(lst[i]) == tuple:\n",
    "            s += ' '.join(lst[i])\n",
    "        else:\n",
    "            s += lst[i]\n",
    "\n",
    "        # Insert a '|' character if i is not the last index.\n",
    "        if i < len(lst)-1:           \n",
    "            s += ', '\n",
    "            \n",
    "    return \"{}\".format(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/seyounglee/Desktop/coding_for_humanists/f23-labs-seyoungleee/Final Project\n",
      "all_comments.txt\n",
      "{'TTR': '0.033479034844986516', 'Wd Length': '4.1601809665650284', 'Word Count': '907792', 'Top 10 words': 'recipe, make, made, added, like, good, time, just, use, add', 'Top 10 bigrams': 'it was, in the, this recipe, of the, i used, the recipe, to make, a little, to the, and i', 'Top 10 trigrams': 'and it was, next time i, easy to make, to make it, followed the recipe, i made it, a lot of, this is a, i used a, it was a'}\n"
     ]
    }
   ],
   "source": [
    "# Input into one final dictionary\n",
    "\n",
    "def one_dict():\n",
    "    print(current_directory)\n",
    "    filename = \"all_comments.txt\"\n",
    "    print(filename)\n",
    "        \n",
    "    # --- DATA ---\n",
    "    # TTR\n",
    "    ttr = get_ttr(filename)\n",
    "\n",
    "    # Average word length\n",
    "    avg_wordlength = avg_word_len(filename)\n",
    "\n",
    "    # Total number of words\n",
    "    word_count = total_num_words(filename)\n",
    "\n",
    "    # Top 10 most frequent words\n",
    "    top10_words = most_freq_words(filename)\n",
    "    top10_words = list_to_str(top10_words)\n",
    "\n",
    "    # Top 10 bigrams\n",
    "    top10_bigrams = top_bigrams(filename)\n",
    "    top10_bigrams = list_to_str(top10_bigrams)\n",
    "\n",
    "    # Top 10 trigrams\n",
    "    top10_trigrams = top_trigrams(filename)\n",
    "    top10_trigrams = list_to_str(top10_trigrams)\n",
    "\n",
    "    row_data = {\"TTR\": f\"{ttr}\",\n",
    "                \"Wd Length\": f\"{avg_wordlength}\",\n",
    "                \"Word Count\": f\"{word_count}\",\n",
    "                \"Top 10 words\": f\"{top10_words}\",\n",
    "                \"Top 10 bigrams\": f\"{top10_bigrams}\",\n",
    "                \"Top 10 trigrams\": f\"{top10_trigrams}\"}\n",
    "    \n",
    "    return row_data\n",
    "\n",
    "print(one_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All family word count: 6308\n",
      "Total word count: 30147\n",
      "{'partner': 7, 'husband': 805, 'wife': 152, 'love': 1359, 'child': 47, 'family': 1225, 'daughter': 131, 'mom': 246, 'girlfriend': 8, 'close': 210, 'house': 199, 'friend': 139, 'holidays': 37, 'holiday': 60, 'mother': 185, 'friends': 204, 'old': 289, 'warm': 214, 'girl': 31, 'son': 112, 'boyfriend': 65, 'sister': 38, 'boy': 20, 'older': 15, 'uncle': 13, 'young': 33, 'father': 25, 'household': 22, 'grandmother': 165, 'cat': 2, 'aunt': 32, 'teen': 5, 'dad': 42, 'granddaughter': 9, 'grandfather': 8, 'grandpa': 6, 'grandson': 11, 'teacher': 5, 'cousin': 6, 'generation': 7, 'niece': 3, 'gathering': 19, 'fiance': 24, 'younger': 6, 'pa': 22, 'brother': 18, 'nephew': 6, 'daddy': 4, 'dog': 6, 'fiancé': 5, 'kin': 1, 'pet': 5}\n"
     ]
    }
   ],
   "source": [
    "# List of family words\n",
    "def get_family_words():\n",
    "    # Open file\n",
    "    fhand = open(f\"{current_directory}/reference_data/family_words.txt\")\n",
    "    family_words = [line.lower() for line in fhand.read().splitlines()]\n",
    "    family_set = set(family_words)\n",
    "\n",
    "    return family_set\n",
    "\n",
    "family_words = get_family_words()\n",
    "\n",
    "# Clean text\n",
    "def cleansed_text2(text):\n",
    "    # Remove digits\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    # Remove punctuations\n",
    "    text = text.translate(text.maketrans('', '', string.punctuation))\n",
    "    # Remove newline\n",
    "    text = text.replace(\"/n\", \" \")\n",
    "    # Tokenize\n",
    "    text = text.split(\" \")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Find family words\n",
    "def find_family():\n",
    "    fhand = open(f\"{current_directory}/all_comments.txt\")\n",
    "    text = fhand.read().lower()\n",
    "    \n",
    "    # Clean text\n",
    "    text_list = cleansed_text2(text)\n",
    "    # Exclude function words\n",
    "    text_nofw = [word for word in text_list if not is_function_word(word)]\n",
    "    \n",
    "    # Frequency of family words\n",
    "    all_count = 0\n",
    "    family_count = dict()\n",
    "    for word in text_nofw:\n",
    "        if word in family_words:\n",
    "            all_count += 1\n",
    "            \n",
    "            if word in family_count:\n",
    "                family_count[word] += 1\n",
    "            else:\n",
    "                family_count[word] = 1\n",
    "                \n",
    "    print(f\"All family word count: {all_count}\")\n",
    "    print(f\"Total word count: {len(set(text_nofw))}\")\n",
    "    return family_count\n",
    "\n",
    "\n",
    "print(find_family())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_newest20.txt\n",
      "all_oldest20.txt\n"
     ]
    }
   ],
   "source": [
    "# Input data into final csv file\n",
    "\n",
    "def final_csv():\n",
    "    all_data = one_dict()\n",
    "    \n",
    "    # Change current directory\n",
    "    cur_directory = os.chdir(f\"{current_directory}/data/{subgroup}\")\n",
    "    \n",
    "    fields = [\"TTR\",\n",
    "              \"Wd Length\", \"Word Count\",\n",
    "              \"Top 10 words\", \"Top 10 bigrams\", \"Top 10 trigrams\"]\n",
    "    \n",
    "    with open(f\"all_comments_stats.csv\", 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fields)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
